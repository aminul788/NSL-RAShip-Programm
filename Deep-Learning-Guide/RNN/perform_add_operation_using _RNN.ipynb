{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence to sequence learning for performing number addition (Perform add operation using RNN)\n",
    "\n",
    "Link: https://keras.io/examples/nlp/addition_rnn/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this example, we train a model to learn to add two numbers, provided as strings.\n",
    "\n",
    "**Example:\n",
    "\n",
    "    Input: \"535+61\"\n",
    "    Output: \"596\"\n",
    "\n",
    "Input may optionally be reversed, which was shown to increase performance in many tasks in: Learning to Execute and [Sequence to Sequence Learning with Neural Networks](\n",
    "\n",
    "http://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf)\n",
    "\n",
    "Theoretically, sequence order inversion introduces shorter term dependencies between source and target for this problem.\n",
    "\n",
    "**Results:\n",
    "\n",
    "For two digits (reversed):\n",
    "\n",
    "    - One layer LSTM (128 HN), 5k training examples = 99% train/test accuracy in 55 epochs\n",
    "\n",
    "Three digits (reversed):\n",
    "\n",
    "    - One layer LSTM (128 HN), 50k training examples = 99% train/test accuracy in 100 epochs\n",
    "\n",
    "Four digits (reversed):\n",
    "\n",
    "    - One layer LSTM (128 HN), 400k training examples = 99% train/test accuracy in 20 epochs\n",
    "\n",
    "Five digits (reversed):\n",
    "\n",
    "    - One layer LSTM (128 HN), 550k training examples = 99% train/test accuracy in 30 epochs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "\n",
    "# Parameters for the model and dataset.\n",
    "TRAINING_SIZE = 50000\n",
    "DIGITS = 3\n",
    "REVERSE = True\n",
    "\n",
    "# Maximum length of input is 'int + int' (e.g., '345+678').\n",
    "# Maximum length of int is DIGITS.\n",
    "MAXLEN = DIGITS + 1 + DIGITS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating data...\n",
      "Total questions: 50000\n"
     ]
    }
   ],
   "source": [
    "class CharacterTable:\n",
    "    \"\"\"Given a set of characters:\n",
    "    + Encode them to a one-hot integer representation\n",
    "    + Decode the one-hot or integer representation to their character output\n",
    "    + Decode a vector of probabilities to their character output\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, chars):\n",
    "        \"\"\"Initialize characcter table.\n",
    "        # Arguments\n",
    "            chars: Characters that can appear in the input.\n",
    "        \"\"\"\n",
    "        self.chars = sorted(set(chars))\n",
    "        self.char_indices = dict((c, i) for i, c in enumerate(self.chars))\n",
    "        self.indices_char = dict((i, c) for i, c in enumerate(self.chars))\n",
    "        \n",
    "    def encode(self, C, num_rows):\n",
    "        \"\"\"One-hot encode given string C.\n",
    "        # Arguments:\n",
    "            C: string, to be encoded.\n",
    "            num_rows: Number of rows in the returned one-hot encoding.\n",
    "                This is used to keep the # of rows for each data the same.\n",
    "        \"\"\"\n",
    "        x = np.zeros((num_rows, len(self.chars)))\n",
    "        for i, c in enumerate(C):\n",
    "            x[i, self.char_indices[c]] = 1\n",
    "        return x\n",
    "    \n",
    "    def decode(self, x, calc_argmax=True):\n",
    "        \"\"\"Decode the given vector or 2D array to their character output.\n",
    "        # Arguments\n",
    "            x: A vector or a 2D array of probabilities or one-hot representations;\n",
    "                or a vector of character indices (used with `calc_argmax=False`).\n",
    "            calc_argmax: Whether to find the character index with maximum\n",
    "                probability, defaults to `True`.\n",
    "        \"\"\"\n",
    "        if calc_argmax:\n",
    "            x = x.argmax(axis=-1)\n",
    "        return \"\".join(self.indices_char[x] for x in x)\n",
    "    \n",
    "    \n",
    "# All the numbers, plus sign and space for padding.\n",
    "chars = \"0123456789+ \"\n",
    "ctable = CharacterTable(chars)\n",
    "\n",
    "questions = []\n",
    "expected = []\n",
    "seen = set()\n",
    "print(\"Generating data...\")\n",
    "while len(questions) < TRAINING_SIZE:\n",
    "    f = lambda: int(\n",
    "        \"\".join(\n",
    "            np.random.choice(list(\"0123456789\"))\n",
    "            for i in range(np.random.randint(1, DIGITS + 1))\n",
    "        )\n",
    "    )\n",
    "    a, b = f(), f()\n",
    "    # Skip any addition questions we've already seen\n",
    "    # Also skip any such that x+Y == Y+x (hence the sorting).\n",
    "    key = tuple(sorted((a, b)))\n",
    "    if key in seen:\n",
    "        continue\n",
    "    seen.add(key)\n",
    "    \n",
    "    # Pad the data with spaces such that it is always MAXLEN.\n",
    "    q = \"{}+{}\".format(a, b)\n",
    "    query = q + \" \" * (MAXLEN - len(q))\n",
    "    ans = str(a + b)\n",
    "    # Answers can be of maximum size DIGITS + 1.\n",
    "    ans += \" \" * (DIGITS + 1 - len(ans))\n",
    "    if REVERSE:\n",
    "        # Reverse the query, e.g., \"12+345 ' becomes ' 543+21\".\n",
    "        # (Note the space used for padding.)\n",
    "        query = query[::-1]\n",
    "    questions.append(query)\n",
    "    expected.append(ans)\n",
    "print(\"Total questions:\", len(questions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorization...\n",
      "Training Data:\n",
      "(45000, 7, 12)\n",
      "(45000, 4, 12)\n",
      "Validation Data:\n",
      "(5000, 7, 12)\n",
      "(5000, 4, 12)\n"
     ]
    }
   ],
   "source": [
    "print(\"Vectorization...\")\n",
    "x = np.zeros((len(questions), MAXLEN, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(questions), DIGITS + 1, len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(questions):\n",
    "    x[i] = ctable.encode(sentence, MAXLEN)\n",
    "for i, sentence in enumerate(expected):\n",
    "    y[i] = ctable.encode(sentence, DIGITS + 1)\n",
    "    \n",
    "# Suffle (x, y) in unison as the later parts of x will almost\n",
    "# all be larger digits.\n",
    "indices = np.arange(len(y))\n",
    "np.random.shuffle(indices)\n",
    "x = x[indices]\n",
    "y = y[indices]\n",
    "\n",
    "# Explicitly set apart 10% for validation data that we never train over.\n",
    "split_at = len(x) - len(x) // 10\n",
    "(x_train, x_val) = x[:split_at], x[split_at:]\n",
    "(y_train, y_val) = y[:split_at], y[split_at:]\n",
    "\n",
    "print(\"Training Data:\")\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print(\"Validation Data:\")\n",
    "print(x_val.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2 (LSTM)                (None, 128)               72192     \n",
      "_________________________________________________________________\n",
      "repeat_vector_2 (RepeatVecto (None, 4, 128)            0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 4, 128)            131584    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4, 12)             1548      \n",
      "=================================================================\n",
      "Total params: 205,324\n",
      "Trainable params: 205,324\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "print(\"Build model...\")\n",
    "num_layers = 1   # Try to add more LSTM layers!\n",
    "\n",
    "model = keras.Sequential()\n",
    "# \"Encode\" the input sequence using a LSTM, producing an output of size 128.\n",
    "# Note: In a situation where our input sequences have a variable length,\n",
    "# use input_shape=(None, num_feature).\n",
    "model.add(layers.LSTM(128, input_shape=(MAXLEN, len(chars))))\n",
    "# As the decoder RNN's input, repeatedly provide with the last output of\n",
    "# RNN for each time step. Repeat 'DIGITS + 1' times as that's the maximum\n",
    "# length of output, e.g., when DIGITS=3, max output is 999+999=1998.\n",
    "model.add(layers.RepeatVector(DIGITS + 1))\n",
    "# The decoder RNN could be multiple layers stacked or a single layer.\n",
    "for _ in range(num_layers):\n",
    "    # By setting return_sequences to True, return not only the last output but\n",
    "    # all the outputs so far in the form of (num_samples, timesteps,\n",
    "    # output_dim). This is necessary as TimeDistributed in the below expects\n",
    "    # the first dimension to be the timesteps.\n",
    "    model.add(layers.LSTM(128, return_sequences=True))\n",
    "    \n",
    "# Apply a dense layer to the every temporal slice of an input. For each of step\n",
    "# of the output sequence, decide which character should be chosen.\n",
    "model.add(layers.Dense(len(chars), activation=\"softmax\"))\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration = 1\n",
      "1407/1407 [==============================] - 28s 20ms/step - loss: 1.7540 - accuracy: 0.3570 - val_loss: 1.5618 - val_accuracy: 0.4153\n",
      "Q 46+352  T 398  ☒ 400 \n",
      "Q 669+291 T 960  ☒ 102 \n",
      "Q 64+475  T 539  ☒ 532 \n",
      "Q 951+879 T 1830 ☒ 1588\n",
      "Q 119+981 T 1100 ☒ 102 \n",
      "Q 46+117  T 163  ☒ 211 \n",
      "Q 27+855  T 882  ☒ 688 \n",
      "Q 791+647 T 1438 ☒ 1333\n",
      "Q 75+413  T 488  ☒ 410 \n",
      "Q 725+8   T 733  ☒ 172 \n",
      "\n",
      "Iteration = 2\n",
      "1407/1407 [==============================] - 26s 19ms/step - loss: 1.3313 - accuracy: 0.5026 - val_loss: 1.1350 - val_accuracy: 0.5760\n",
      "Q 8+248   T 256  ☒ 259 \n",
      "Q 963+41  T 1004 ☒ 901 \n",
      "Q 422+9   T 431  ☒ 430 \n",
      "Q 555+652 T 1207 ☒ 1211\n",
      "Q 56+560  T 616  ☒ 614 \n",
      "Q 88+60   T 148  ☒ 144 \n",
      "Q 944+84  T 1028 ☒ 1024\n",
      "Q 439+425 T 864  ☒ 764 \n",
      "Q 26+333  T 359  ☒ 361 \n",
      "Q 324+768 T 1092 ☒ 1011\n",
      "\n",
      "Iteration = 3\n",
      "1407/1407 [==============================] - 29s 20ms/step - loss: 1.0154 - accuracy: 0.6248 - val_loss: 0.9277 - val_accuracy: 0.6532\n",
      "Q 14+741  T 755  ☒ 747 \n",
      "Q 315+8   T 323  ☒ 324 \n",
      "Q 91+95   T 186  ☒ 176 \n",
      "Q 0+578   T 578  ☒ 574 \n",
      "Q 557+966 T 1523 ☒ 1419\n",
      "Q 246+201 T 447  ☒ 449 \n",
      "Q 356+454 T 810  ☒ 818 \n",
      "Q 238+59  T 297  ☒ 295 \n",
      "Q 239+729 T 968  ☒ 977 \n",
      "Q 43+972  T 1015 ☒ 1018\n",
      "\n",
      "Iteration = 4\n",
      "1407/1407 [==============================] - 27s 19ms/step - loss: 0.8342 - accuracy: 0.6940 - val_loss: 0.7628 - val_accuracy: 0.7212\n",
      "Q 596+378 T 974  ☒ 968 \n",
      "Q 717+225 T 942  ☒ 930 \n",
      "Q 169+5   T 174  ☒ 172 \n",
      "Q 735+6   T 741  ☒ 740 \n",
      "Q 899+372 T 1271 ☒ 1265\n",
      "Q 6+882   T 888  ☑ 888 \n",
      "Q 659+806 T 1465 ☒ 1470\n",
      "Q 29+941  T 970  ☒ 978 \n",
      "Q 12+924  T 936  ☒ 930 \n",
      "Q 18+77   T 95   ☑ 95  \n",
      "\n",
      "Iteration = 5\n",
      "1407/1407 [==============================] - 26s 19ms/step - loss: 0.7019 - accuracy: 0.7476 - val_loss: 0.6372 - val_accuracy: 0.7702\n",
      "Q 951+122 T 1073 ☒ 1065\n",
      "Q 13+738  T 751  ☒ 750 \n",
      "Q 71+592  T 663  ☒ 660 \n",
      "Q 70+236  T 306  ☒ 308 \n",
      "Q 534+78  T 612  ☒ 611 \n",
      "Q 851+619 T 1470 ☒ 1472\n",
      "Q 600+210 T 810  ☒ 823 \n",
      "Q 89+41   T 130  ☒ 131 \n",
      "Q 472+479 T 951  ☒ 943 \n",
      "Q 363+82  T 445  ☒ 443 \n",
      "\n",
      "Iteration = 6\n",
      "1407/1407 [==============================] - 26s 19ms/step - loss: 0.5197 - accuracy: 0.8130 - val_loss: 0.3792 - val_accuracy: 0.8691\n",
      "Q 77+984  T 1061 ☒ 1062\n",
      "Q 877+4   T 881  ☑ 881 \n",
      "Q 465+606 T 1071 ☑ 1071\n",
      "Q 824+306 T 1130 ☒ 1120\n",
      "Q 61+852  T 913  ☒ 914 \n",
      "Q 357+1   T 358  ☑ 358 \n",
      "Q 731+83  T 814  ☑ 814 \n",
      "Q 18+251  T 269  ☒ 279 \n",
      "Q 56+585  T 641  ☑ 641 \n",
      "Q 0+755   T 755  ☑ 755 \n",
      "\n",
      "Iteration = 7\n",
      "1407/1407 [==============================] - 27s 19ms/step - loss: 0.2869 - accuracy: 0.9129 - val_loss: 0.2062 - val_accuracy: 0.9460\n",
      "Q 51+454  T 505  ☑ 505 \n",
      "Q 107+412 T 519  ☑ 519 \n",
      "Q 31+639  T 670  ☑ 670 \n",
      "Q 79+14   T 93   ☒ 92  \n",
      "Q 660+848 T 1508 ☑ 1508\n",
      "Q 43+504  T 547  ☑ 547 \n",
      "Q 716+815 T 1531 ☒ 1530\n",
      "Q 131+775 T 906  ☑ 906 \n",
      "Q 468+295 T 763  ☑ 763 \n",
      "Q 72+84   T 156  ☑ 156 \n",
      "\n",
      "Iteration = 8\n",
      "1407/1407 [==============================] - 26s 19ms/step - loss: 0.1714 - accuracy: 0.9577 - val_loss: 0.1464 - val_accuracy: 0.9599\n",
      "Q 118+682 T 800  ☑ 800 \n",
      "Q 893+34  T 927  ☑ 927 \n",
      "Q 761+78  T 839  ☑ 839 \n",
      "Q 911+620 T 1531 ☒ 1530\n",
      "Q 388+91  T 479  ☑ 479 \n",
      "Q 102+3   T 105  ☑ 105 \n",
      "Q 561+7   T 568  ☑ 568 \n",
      "Q 73+698  T 771  ☑ 771 \n",
      "Q 794+47  T 841  ☑ 841 \n",
      "Q 89+251  T 340  ☑ 340 \n",
      "\n",
      "Iteration = 9\n",
      "1407/1407 [==============================] - 26s 19ms/step - loss: 0.1153 - accuracy: 0.9713 - val_loss: 0.0973 - val_accuracy: 0.9749\n",
      "Q 853+883 T 1736 ☑ 1736\n",
      "Q 0+200   T 200  ☑ 200 \n",
      "Q 99+464  T 563  ☑ 563 \n",
      "Q 567+22  T 589  ☑ 589 \n",
      "Q 187+8   T 195  ☑ 195 \n",
      "Q 55+275  T 330  ☑ 330 \n",
      "Q 622+92  T 714  ☑ 714 \n",
      "Q 490+350 T 840  ☑ 840 \n",
      "Q 682+422 T 1104 ☑ 1104\n",
      "Q 167+914 T 1081 ☑ 1081\n",
      "\n",
      "Iteration = 10\n",
      "1407/1407 [==============================] - 27s 19ms/step - loss: 0.0966 - accuracy: 0.9747 - val_loss: 0.0804 - val_accuracy: 0.9796\n",
      "Q 854+12  T 866  ☑ 866 \n",
      "Q 51+721  T 772  ☑ 772 \n",
      "Q 76+713  T 789  ☒ 799 \n",
      "Q 818+25  T 843  ☑ 843 \n",
      "Q 442+296 T 738  ☑ 738 \n",
      "Q 872+80  T 952  ☑ 952 \n",
      "Q 20+34   T 54   ☑ 54  \n",
      "Q 0+130   T 130  ☑ 130 \n",
      "Q 82+623  T 705  ☑ 705 \n",
      "Q 13+79   T 92   ☑ 92  \n",
      "\n",
      "Iteration = 11\n",
      "1407/1407 [==============================] - 27s 19ms/step - loss: 0.0581 - accuracy: 0.9869 - val_loss: 0.0462 - val_accuracy: 0.9893\n",
      "Q 317+50  T 367  ☑ 367 \n",
      "Q 669+8   T 677  ☑ 677 \n",
      "Q 50+390  T 440  ☑ 440 \n",
      "Q 291+23  T 314  ☑ 314 \n",
      "Q 15+437  T 452  ☑ 452 \n",
      "Q 60+450  T 510  ☑ 510 \n",
      "Q 761+78  T 839  ☑ 839 \n",
      "Q 88+39   T 127  ☑ 127 \n",
      "Q 851+619 T 1470 ☑ 1470\n",
      "Q 515+15  T 530  ☑ 530 \n",
      "\n",
      "Iteration = 12\n",
      "1407/1407 [==============================] - 27s 19ms/step - loss: 0.0482 - accuracy: 0.9885 - val_loss: 0.0313 - val_accuracy: 0.9941\n",
      "Q 74+381  T 455  ☑ 455 \n",
      "Q 793+510 T 1303 ☒ 1203\n",
      "Q 23+589  T 612  ☑ 612 \n",
      "Q 88+521  T 609  ☑ 609 \n",
      "Q 19+497  T 516  ☑ 516 \n",
      "Q 116+988 T 1104 ☑ 1104\n",
      "Q 40+313  T 353  ☑ 353 \n",
      "Q 4+612   T 616  ☑ 616 \n",
      "Q 0+43    T 43   ☑ 43  \n",
      "Q 21+884  T 905  ☑ 905 \n",
      "\n",
      "Iteration = 13\n",
      "1407/1407 [==============================] - 27s 19ms/step - loss: 0.0534 - accuracy: 0.9857 - val_loss: 0.0434 - val_accuracy: 0.9883\n",
      "Q 51+719  T 770  ☑ 770 \n",
      "Q 66+27   T 93   ☑ 93  \n",
      "Q 79+365  T 444  ☑ 444 \n",
      "Q 777+76  T 853  ☑ 853 \n",
      "Q 473+402 T 875  ☑ 875 \n",
      "Q 70+275  T 345  ☑ 345 \n",
      "Q 8+642   T 650  ☑ 650 \n",
      "Q 9+922   T 931  ☑ 931 \n",
      "Q 96+65   T 161  ☑ 161 \n",
      "Q 2+120   T 122  ☑ 122 \n",
      "\n",
      "Iteration = 14\n",
      "1407/1407 [==============================] - 27s 19ms/step - loss: 0.0284 - accuracy: 0.9940 - val_loss: 0.0219 - val_accuracy: 0.9962\n",
      "Q 165+832 T 997  ☑ 997 \n",
      "Q 30+972  T 1002 ☑ 1002\n",
      "Q 0+47    T 47   ☑ 47  \n",
      "Q 720+21  T 741  ☑ 741 \n",
      "Q 83+303  T 386  ☑ 386 \n",
      "Q 552+188 T 740  ☑ 740 \n",
      "Q 151+74  T 225  ☑ 225 \n",
      "Q 620+87  T 707  ☑ 707 \n",
      "Q 27+561  T 588  ☑ 588 \n",
      "Q 981+82  T 1063 ☑ 1063\n",
      "\n",
      "Iteration = 15\n",
      "1407/1407 [==============================] - 27s 19ms/step - loss: 0.0416 - accuracy: 0.9890 - val_loss: 0.0150 - val_accuracy: 0.9971\n",
      "Q 220+5   T 225  ☑ 225 \n",
      "Q 42+306  T 348  ☑ 348 \n",
      "Q 964+0   T 964  ☑ 964 \n",
      "Q 286+810 T 1096 ☑ 1096\n",
      "Q 267+5   T 272  ☑ 272 \n",
      "Q 341+294 T 635  ☑ 635 \n",
      "Q 0+755   T 755  ☑ 755 \n",
      "Q 513+284 T 797  ☑ 797 \n",
      "Q 9+411   T 420  ☑ 420 \n",
      "Q 9+326   T 335  ☑ 335 \n",
      "\n",
      "Iteration = 16\n",
      "1407/1407 [==============================] - 27s 19ms/step - loss: 0.0311 - accuracy: 0.9919 - val_loss: 0.0152 - val_accuracy: 0.9969\n",
      "Q 966+98  T 1064 ☑ 1064\n",
      "Q 124+67  T 191  ☑ 191 \n",
      "Q 95+527  T 622  ☑ 622 \n",
      "Q 52+57   T 109  ☑ 109 \n",
      "Q 374+14  T 388  ☑ 388 \n",
      "Q 409+151 T 560  ☑ 560 \n",
      "Q 274+17  T 291  ☑ 291 \n",
      "Q 34+852  T 886  ☑ 886 \n",
      "Q 421+682 T 1103 ☑ 1103\n",
      "Q 221+193 T 414  ☑ 414 \n",
      "\n",
      "Iteration = 17\n",
      "1407/1407 [==============================] - 27s 19ms/step - loss: 0.0294 - accuracy: 0.9922 - val_loss: 0.0160 - val_accuracy: 0.9966\n",
      "Q 772+938 T 1710 ☑ 1710\n",
      "Q 39+680  T 719  ☑ 719 \n",
      "Q 73+698  T 771  ☑ 771 \n",
      "Q 0+937   T 937  ☑ 937 \n",
      "Q 133+449 T 582  ☑ 582 \n",
      "Q 491+47  T 538  ☑ 538 \n",
      "Q 867+20  T 887  ☑ 887 \n",
      "Q 42+105  T 147  ☑ 147 \n",
      "Q 918+76  T 994  ☑ 994 \n",
      "Q 516+44  T 560  ☑ 560 \n",
      "\n",
      "Iteration = 18\n",
      "1407/1407 [==============================] - 27s 19ms/step - loss: 0.0335 - accuracy: 0.9908 - val_loss: 0.0337 - val_accuracy: 0.9904\n",
      "Q 1+748   T 749  ☑ 749 \n",
      "Q 886+1   T 887  ☑ 887 \n",
      "Q 47+318  T 365  ☑ 365 \n",
      "Q 133+449 T 582  ☑ 582 \n",
      "Q 348+393 T 741  ☑ 741 \n",
      "Q 4+196   T 200  ☑ 200 \n",
      "Q 5+916   T 921  ☑ 921 \n",
      "Q 87+981  T 1068 ☑ 1068\n",
      "Q 109+943 T 1052 ☒ 1051\n",
      "Q 124+592 T 716  ☑ 716 \n",
      "\n",
      "Iteration = 19\n",
      "1407/1407 [==============================] - 27s 19ms/step - loss: 0.0153 - accuracy: 0.9965 - val_loss: 0.0682 - val_accuracy: 0.9764\n",
      "Q 856+34  T 890  ☑ 890 \n",
      "Q 89+499  T 588  ☑ 588 \n",
      "Q 1+930   T 931  ☑ 931 \n",
      "Q 5+764   T 769  ☑ 769 \n",
      "Q 687+387 T 1074 ☑ 1074\n",
      "Q 26+229  T 255  ☑ 255 \n",
      "Q 256+118 T 374  ☑ 374 \n",
      "Q 439+67  T 506  ☑ 506 \n",
      "Q 238+59  T 297  ☑ 297 \n",
      "Q 512+1   T 513  ☑ 513 \n",
      "\n",
      "Iteration = 20\n",
      "1407/1407 [==============================] - 27s 19ms/step - loss: 0.0265 - accuracy: 0.9926 - val_loss: 0.0286 - val_accuracy: 0.9915\n",
      "Q 12+238  T 250  ☑ 250 \n",
      "Q 531+679 T 1210 ☑ 1210\n",
      "Q 579+97  T 676  ☑ 676 \n",
      "Q 494+0   T 494  ☑ 494 \n",
      "Q 191+865 T 1056 ☑ 1056\n",
      "Q 78+6    T 84   ☑ 84  \n",
      "Q 58+93   T 151  ☑ 151 \n",
      "Q 12+658  T 670  ☑ 670 \n",
      "Q 726+967 T 1693 ☑ 1693\n",
      "Q 687+534 T 1221 ☑ 1221\n",
      "\n",
      "Iteration = 21\n",
      "1407/1407 [==============================] - 27s 19ms/step - loss: 0.0345 - accuracy: 0.9903 - val_loss: 0.0133 - val_accuracy: 0.9975\n",
      "Q 140+8   T 148  ☑ 148 \n",
      "Q 326+328 T 654  ☑ 654 \n",
      "Q 389+77  T 466  ☑ 466 \n",
      "Q 51+76   T 127  ☑ 127 \n",
      "Q 530+973 T 1503 ☑ 1503\n",
      "Q 732+98  T 830  ☑ 830 \n",
      "Q 89+39   T 128  ☑ 128 \n",
      "Q 227+525 T 752  ☑ 752 \n",
      "Q 406+7   T 413  ☑ 413 \n",
      "Q 862+8   T 870  ☑ 870 \n",
      "\n",
      "Iteration = 22\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1407/1407 [==============================] - 24s 17ms/step - loss: 0.0065 - accuracy: 0.9990 - val_loss: 0.0557 - val_accuracy: 0.9826\n",
      "Q 61+452  T 513  ☑ 513 \n",
      "Q 904+32  T 936  ☑ 936 \n",
      "Q 4+930   T 934  ☑ 934 \n",
      "Q 9+549   T 558  ☑ 558 \n",
      "Q 809+3   T 812  ☑ 812 \n",
      "Q 15+26   T 41   ☑ 41  \n",
      "Q 7+957   T 964  ☑ 964 \n",
      "Q 583+15  T 598  ☑ 598 \n",
      "Q 5+884   T 889  ☑ 889 \n",
      "Q 999+504 T 1503 ☒ 1403\n",
      "\n",
      "Iteration = 23\n",
      "1407/1407 [==============================] - 24s 17ms/step - loss: 0.0200 - accuracy: 0.9945 - val_loss: 0.0063 - val_accuracy: 0.9990\n",
      "Q 118+3   T 121  ☑ 121 \n",
      "Q 998+99  T 1097 ☑ 1097\n",
      "Q 494+263 T 757  ☑ 757 \n",
      "Q 6+289   T 295  ☑ 295 \n",
      "Q 84+645  T 729  ☑ 729 \n",
      "Q 54+687  T 741  ☑ 741 \n",
      "Q 407+337 T 744  ☑ 744 \n",
      "Q 512+782 T 1294 ☑ 1294\n",
      "Q 8+694   T 702  ☑ 702 \n",
      "Q 424+84  T 508  ☑ 508 \n",
      "\n",
      "Iteration = 24\n",
      "1407/1407 [==============================] - 24s 17ms/step - loss: 0.0251 - accuracy: 0.9931 - val_loss: 0.0082 - val_accuracy: 0.9982\n",
      "Q 453+71  T 524  ☑ 524 \n",
      "Q 101+256 T 357  ☑ 357 \n",
      "Q 798+74  T 872  ☑ 872 \n",
      "Q 933+591 T 1524 ☑ 1524\n",
      "Q 56+421  T 477  ☑ 477 \n",
      "Q 677+463 T 1140 ☑ 1140\n",
      "Q 61+402  T 463  ☑ 463 \n",
      "Q 340+0   T 340  ☑ 340 \n",
      "Q 97+698  T 795  ☑ 795 \n",
      "Q 63+95   T 158  ☑ 158 \n",
      "\n",
      "Iteration = 25\n",
      "1407/1407 [==============================] - 24s 17ms/step - loss: 0.0027 - accuracy: 0.9998 - val_loss: 0.0051 - val_accuracy: 0.9990\n",
      "Q 550+191 T 741  ☑ 741 \n",
      "Q 985+62  T 1047 ☑ 1047\n",
      "Q 58+790  T 848  ☑ 848 \n",
      "Q 69+371  T 440  ☑ 440 \n",
      "Q 26+229  T 255  ☑ 255 \n",
      "Q 56+328  T 384  ☑ 384 \n",
      "Q 82+633  T 715  ☑ 715 \n",
      "Q 244+872 T 1116 ☑ 1116\n",
      "Q 573+89  T 662  ☑ 662 \n",
      "Q 464+296 T 760  ☑ 760 \n",
      "\n",
      "Iteration = 26\n",
      "1407/1407 [==============================] - 25s 17ms/step - loss: 0.0320 - accuracy: 0.9915 - val_loss: 0.0054 - val_accuracy: 0.9991\n",
      "Q 657+52  T 709  ☑ 709 \n",
      "Q 67+992  T 1059 ☑ 1059\n",
      "Q 12+777  T 789  ☑ 789 \n",
      "Q 12+622  T 634  ☑ 634 \n",
      "Q 500+393 T 893  ☑ 893 \n",
      "Q 86+474  T 560  ☑ 560 \n",
      "Q 575+997 T 1572 ☑ 1572\n",
      "Q 93+445  T 538  ☑ 538 \n",
      "Q 450+17  T 467  ☑ 467 \n",
      "Q 54+862  T 916  ☑ 916 \n",
      "\n",
      "Iteration = 27\n",
      "1407/1407 [==============================] - 24s 17ms/step - loss: 0.0166 - accuracy: 0.9952 - val_loss: 0.0098 - val_accuracy: 0.9976\n",
      "Q 37+557  T 594  ☑ 594 \n",
      "Q 88+276  T 364  ☑ 364 \n",
      "Q 51+787  T 838  ☑ 838 \n",
      "Q 569+964 T 1533 ☑ 1533\n",
      "Q 849+266 T 1115 ☑ 1115\n",
      "Q 60+760  T 820  ☑ 820 \n",
      "Q 54+596  T 650  ☑ 650 \n",
      "Q 40+313  T 353  ☑ 353 \n",
      "Q 6+984   T 990  ☑ 990 \n",
      "Q 70+986  T 1056 ☑ 1056\n",
      "\n",
      "Iteration = 28\n",
      "1407/1407 [==============================] - 25s 17ms/step - loss: 0.0230 - accuracy: 0.9936 - val_loss: 0.0259 - val_accuracy: 0.9923\n",
      "Q 2+24    T 26   ☑ 26  \n",
      "Q 397+81  T 478  ☑ 478 \n",
      "Q 758+948 T 1706 ☑ 1706\n",
      "Q 382+5   T 387  ☑ 387 \n",
      "Q 778+18  T 796  ☑ 796 \n",
      "Q 792+14  T 806  ☑ 806 \n",
      "Q 394+881 T 1275 ☑ 1275\n",
      "Q 69+858  T 927  ☑ 927 \n",
      "Q 477+634 T 1111 ☑ 1111\n",
      "Q 98+796  T 894  ☑ 894 \n",
      "\n",
      "Iteration = 29\n",
      "1407/1407 [==============================] - 26s 19ms/step - loss: 0.0133 - accuracy: 0.9965 - val_loss: 0.0133 - val_accuracy: 0.9963\n",
      "Q 530+869 T 1399 ☑ 1399\n",
      "Q 57+99   T 156  ☑ 156 \n",
      "Q 968+757 T 1725 ☑ 1725\n",
      "Q 94+32   T 126  ☑ 126 \n",
      "Q 2+57    T 59   ☑ 59  \n",
      "Q 815+49  T 864  ☑ 864 \n",
      "Q 13+40   T 53   ☑ 53  \n",
      "Q 702+49  T 751  ☑ 751 \n",
      "Q 56+333  T 389  ☑ 389 \n",
      "Q 7+122   T 129  ☑ 129 \n"
     ]
    }
   ],
   "source": [
    "epochs = 30\n",
    "batch_size = 32\n",
    "\n",
    "# Train the model each generation and show predictions against\n",
    "# the validation dataset.\n",
    "for epoch in range(1, epochs):\n",
    "    print()\n",
    "    print(\"Iteration =\", epoch)\n",
    "    model.fit(\n",
    "        x_train,\n",
    "        y_train,\n",
    "        batch_size=batch_size,\n",
    "        epochs=1,\n",
    "        validation_data=(x_val, y_val),\n",
    "    )\n",
    "    \n",
    "    # Select 10 samples from the validation set at random\n",
    "    # so we can visualize erroirs.\n",
    "    for i in range(10):\n",
    "        ind = np.random.randint(0, len(x_val))\n",
    "        rowx, rowy = x_val[np.array([ind])], y_val[np.array([ind])]\n",
    "        preds = np.argmax(model.predict(rowx), axis=-1)\n",
    "        q = ctable.decode(rowx[0])\n",
    "        correct = ctable.decode(rowy[0])\n",
    "        guess = ctable.decode(preds[0], calc_argmax=False)\n",
    "        print(\"Q\", q[::-1] if REVERSE else q, end=\" \")\n",
    "        print(\"T\", correct, end=\" \")\n",
    "        if correct == guess:\n",
    "            print(\"☑ \" + guess)\n",
    "        else:\n",
    "            print(\"☒ \" + guess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved to /home/nsl20/Desktop/Aminul(me)/Deep-Learning-Guide/RNN & LSTM\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "model_name = 'add_operation_using_rnn.h5'\n",
    "model.save(model_name)\n",
    "print('model saved to', os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
